<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>First Note</title>
    <style>
      body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; max-width: 820px; margin: 48px auto; padding: 0 16px; line-height: 1.6; }
      a { text-decoration: none; }
      a:hover { text-decoration: underline; }
      code { background: #f6f6f6; padding: 2px 6px; border-radius: 6px; }
      pre { background: #f6f6f6; padding: 12px; border-radius: 10px; overflow-x: auto; }
    </style>
  </head>
  <body>
    <p><a href="../index.html">← Back home</a></p>
    <h1>What I’m building</h1>
    <p><em>Jan 12, 2026</em></p>

    <p>
      This site is where I post short learnings on model compression and ML systems — especially
      practical trade-offs like speed vs accuracy, kernel bottlenecks, and deployment.
    </p>

    <h2>Current focus</h2>
    <ul>
      <li>Structured pruning that actually improves GPU latency</li>
      <li>Custom kernels (Triton) for sparse–dense matmul</li>
      <li>Token routing / pruning for multimodal models</li>
    </ul>

    <h2>Example snippet</h2>
    <pre><code># rule of thumb
# if your sparsity doesn't map to hardware-friendly blocks,
# your "FLOPs drop" won't become real speedup.</code></pre>
  </body>
</html>
